> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/E6vNlowbrtJ7j7BvcOJuHw)

![](https://mmbiz.qpic.cn/mmbiz_png/mpfXeUqqSE8YcXXEE6Tj62xuMSLB3MSyulzHTJA0iamVH1A6HJnLQIIvyBiamWhfXPW5xiburlVv0glmCNRMCxLkQ/640?wx_fmt=png&from=appmsg)

**Android**

**音视频流媒体**

基础

流媒体开发中，流媒体系统的实现从数据采集、编码封装、传输分发、接收解码播放都有哪些技术和实现，流媒体和本地音视频又有哪些差异？

流媒体和多媒体

影像系统开发，流媒体方向和普通的多媒体影像系统开发有一定差异。

相同点在于图像多媒体处理以及编程系统等通用方面；本文重点梳理出差异的部分，差异主要在于影像系统在流媒体需要掌握流媒体协议 rtsp 以及流媒体框架 GStreamer，在链路流程上增加了传输分发部分，在软件系统设计上注重负载均以及高并发低延迟。

-------------------------------------------------------

流媒体技术通过实时传输音视频数据应用广泛，主要涉及直播 / 短视频平台、视频会议、智能安防等几大类。最近几年的观察，具体来说在直播摄像头、会议摄像头、智能家具摄像头都有很多产品推出。

更新说明

**本文为了补之前介绍多媒体框架时埋得坑，流媒体在音视频处理上会有一些差异，所以单独拉出来一章来补充。**

**一**

流媒体综述

![](https://mmbiz.qpic.cn/mmbiz_jpg/mpfXeUqqSE8YcXXEE6Tj62xuMSLB3MSyDNn41mfzDtDjVaEkuYeBxLZx9J3H5IkuZqkQj0pptLqHWZR1ib3G3sw/640?wx_fmt=jpeg&from=appmsg)

流媒体开发除了编程及嵌入式技术外还需要掌握影像技术。嵌入式系统开发技术涵盖了硬件设计、软件编程、系统调试等多个方面。

**在整理流媒体的数据链路上，把流媒体技术根据是否通用分为两大类，流媒体的特点主要在于网络传输，所以如果你要面试流媒体相关岗位除了影像的通用知识，最好温习一些网络协议、流媒体协议和框架的知识。**

**1.1**

音视频通用

（1）采集

流媒体的采集模块负责从摄像头、麦克风等输入设备采集原始的音视频数据。

流媒体和多媒体的音视频采集和处理的基础逻辑是相通的，比如图像的 3A、降噪增强以及音频的回声消除 AEC、噪声抑制 NS、自动增益控制 AGC。

流媒体在采集模块会重点考虑支持不同分辨率帧率的多摄像头设备适配。

（2）编码

流媒体编码模块将采集到的原始音视频数据进行编码处理，压缩成适合网络传输的数据流。

音视频编码是将原始的音视频数据压缩为较小的数据流，以便于传输和存储。这一技术对于减少带宽占用、提高传输效率很重要。

常用的音视频编码标准包括 H.264、H.265HEVC 等视频编码标准和 AAC、MP3 等音频编码标准。同时会借用平台的能力来降低 CPU 负载，如 NVIDIA NVENC、MediaTek APU 等等。

（3）封装

封装模块将编码后的音视频数据按照特定的格式进行封装，如 FLV、MP4 等容器格式，可以用来本地存储播放，也可以用于网络传输和播放。

（4）解码

解码播放模块在接收端，流媒体接收就用用户端，不同于本地芯片内完成编码解码，流媒体的编码解码在不同设备完成。接收端析接收到的音视频数据，进行解码处理，并将解码后的音视频数据传递给播放器进行播放。

**1.2**

流媒体关键技术

（1）传输

流媒体传输模块利用流媒体传输协议将封装好的音视频数据发送到服务器或接收端。处理网络传输中的各种问题，如丢包延迟等。

流媒体传输协议负责将编码后的音视频数据从发送端传输到接收端，同时兼顾了实时数据流的传输控制、错误恢复和同步等功能。

常见的流媒体传输协议包括 RTSP 实时流协议、RTP 实时传输协议、HTTP Live Streaming 等等，传输协议的基础则是网络通信技术包括 TCP/IP、Wi-Fi、蓝牙等。

（2）转发

流媒体服务端使用支持 RTMP/HLS/WebRTC 协议的流媒体服务器 SRS 或者 Nginx-RTMP，通过分布式框架利用 CDN 智能调用，兼顾负载均衡 Nginx/HAProxy，实现高并发低时延。

（3）接收

流媒体客户端接收到媒体数据后，软件使用 Android MediaCodec 的 API 实现解码，以及利用 PTS/DTS 时间戳实现音视频同步。

（4）多媒体框架

多媒体框架是嵌入式系统中实现音视频播放和录制的软件架构，比如 GStreamer 架构提供了丰富的音视频处理功能，包括解码、编码、转码、流媒体处理等。

而我们常说的推流则只是框架中的一环，可以使用 GStreamer 实现，也可以通过专用推流框架 OBS Studio/WebRTC 实现更加快速。

**二**

流媒体框架 GStreamer

![](https://mmbiz.qpic.cn/mmbiz_jpg/mpfXeUqqSE8YcXXEE6Tj62xuMSLB3MSyJ3iaDaXlcD1t4CHdhx5sFyYUMzEvNS20VQzLBibmNMrVS1NAE3sTibHew/640?wx_fmt=jpeg&from=appmsg)

在不同的应用场景下，音视频嵌入式系统所使用的新媒体播放和流媒体框架会有所不同。

流媒体框架主要用于实时传输和处理音视频数据，比如视频监控、网络直播等领域。

GStreamer 是一个开源的多媒体框架，基于管道设计，采用 C 语言开发，支持跨平台，提供了处理流媒体的管道架构和音视频处理能力。它的特点是利用插件架构，可以方便地扩展功能，包括编码方式、封装格式等。

**GStreamer 的管道架构是通过链接多个 elements 构成 pipeline 来处理多媒体内容，用于音频录制、转码、播放以及视频流传输等多种场景。**

针对显示和渲染，GStreamer 也是通过其插件系统来实现的。比如有专门的视频 sink 插件 xvimagesink 进行视频渲染，负责将视频帧输出到屏幕上。

GStreamer 插件机制可以实现非常多的格式支持和处理能力，不仅用于流媒体服务器、多媒体播放器等，在整个图像软件的处理过程中都广泛的使用。

**2.1**

框架代码

（1）配置环境，从官网站下载 GStreamer 的 Android 开发包，并按照官方文档进行配置，一般都是集成好的。

（2）集成，在项目的 build.gradle 文件中添加相应的依赖，或者更多将 GStreamer 的库直接集成到项目中。

（3）编写处理代码，使用 GStreamer 提供的 API 和插件来实现具体的音视频处理功能。

使用 gst_parse_launch() 函数来创建和配置 GStreamer 的 pipeline，通过添加不同的 elements（如 source、sink、filter 等）来实现音视频数据的捕获、处理、传输等功能，软件使用它的核心就是掌握这些 elements，这和我们掌握 ISP 的 pipeline 同理。

（4）编译和运行，将编写的代码保存并编译，并连接了硬件设备麦克风和摄像头。使用调试工具测试音视频处理功能是否正常工作。

**2.2**

框架的使用

1）音视频录制，在插件体系中，配置不同的音频源和音频格式，配置不同的视频格式，满足不同的录制需求。

（2）视频流传输，GStreamer RTSP 服务器是一种基于 GStreamer 框架的实时流传输协议 RTSP 的服务器，可用于在 Android 平台上进行音视频流的传输和处理。

（3）音视频转码，利用插件实现音视频数据的转码功能，根据需要将音视频数据转换为不同的格式或编码，以满足不同的播放或存储需求。

（4）视频播放，支持 MP4、AVI 等多种视频格式的解码和播放，集成到安卓应用中，实现视频文件的本地播放或网络流媒体播放。

（5）音视频剪辑与编辑，底层可以通过 GStreamer 的插件和 API，还可以实现音视频数据的剪辑、合并、添加滤镜等编辑功能。

**三**

流媒体协议 RTSP

在嵌入式系统中，常使用实时流协议 RTSP 和 RTMP 实时消息传输协议协议来实现流媒体传输。这些协议允许客户端从服务器接收音视频流，并实时播放。

RTSP（Real Time Streaming Protocol）其实是 TCP/IP 协议体系中的一个应用层协议，不同于我们学习时考究的传输层，该协议主要用于控制声音或影像的多媒体串流，允许同时多个串流需求控制，从而支持实时流媒体应用。

**3.1**

RTSP 特点

（1）双向：与 HTTP 的单向不同，RTSP 协议是双向的。RTSP 在交互过程中，客户机和服务器都可以发出请求。

（2）实时：RTSP 设计用于实时流媒体传输，具有较低的延迟，满足实时交互的应用场景。

（3）独立：在传输层上，RTSP 独立于 RTP 和 RTCP 又相互配合。RTSP 控制媒体流的传输，RTP 和 RTCP 则负责实际的数据传输和质量控制。

（4）功能：RTSP 不仅用于传输数据，它还允许客户端控制媒体流的播放，如播放、暂停、快进、快退等。

**3.2**

RTSP 工作流

RTSP 的核心工作流总结下来就以下几点，

（1）OPTIONS：客户端发送 OPTIONS 请求，get 以了解服务器支持哪些方法；

（2）DESCRIBE：客户端发送 DESCRIBE 请求，get 媒体资源的描述信息，比如编码分辨率等，服务器则返回媒体资源的 SDP 格式的描述信息。

（3）SETUP：客户端发送 SETUP 请求，用于建立媒体会话，指定传输通道协议 UDP 并请求分配端口，服务器则指定媒体流的传输通道和端口。

（4）PLAY：客户端发送 PLAY 请求，以开始媒体流的播放。服务器确认 PLAY 请求，并启动媒体流的传输。

（5）TEARDOWN：当媒体会话结束时，客户端发送 TEARDOWN 请求以终止会话，服务器确认并释放相关资源。

**四**

流媒体应用

![](https://mmbiz.qpic.cn/mmbiz_jpg/mpfXeUqqSE8YcXXEE6Tj62xuMSLB3MSyeClvfU1JP2xic4guw5w9XxM7g6Gial5xjkyTrq0Qwa1ticW2Ur9hfnw3Q/640?wx_fmt=jpeg&from=appmsg)

RTSP 广泛应用于需要实时流媒体传输的场景，如视频监控、视频会议、直播和点播服务、流媒体服务器、媒体播放器等。

**4.1**

安防监控

安防监控摄像头可以将实时视频流传输到监控中心或客户端，实现远程监控和实时查看。

安防监控框架需要具有高实时性、高稳定性和高可靠性，以确保监控视频能够实时、准确地传输和存储。需要支持多种视频编码格式和网络协议，以适应不同的监控需求和网络环境。

这些系统通常由摄像头、视频录像设备和嵌入式处理器组成，通过与传感器相结合，实现图像传输、分析和存储等功能。

除了使用自研专有框架，开源框架 GStreamer 也可用于安防监控系统，以实现跨平台的视频流处理和传输。

**4.2**

视频会议

视频会议框架需要具有低延迟、高清晰度和良好的同步性能，以确保音视频数据的实时传输和播放。

视频会议系统需要实现音视频数据的实时传输和同步播放，以确保参会人员能够清晰地看到和听到对方的发言。

除了使用自研专有框架，开源框架 WebRTC 支持网页浏览器进行实时音视频通信的项目也可以用于视频会议，提供了完整的流媒体功能。

**4.3**

直播和服务器

直播观众可以同步实时观看，需要保证低时延和高可靠性，内容生成和播放同时进行，自动调整码率，以确保观众能够实时流畅的观看直播内容。

直播系统完整流程：主播用 OBS 推流 RTMP 协议→ 流媒体服务器 SRS 接收并转封装为 HLS → CDN 分发 → 观众通过播放器 Video.js 拉流观看。

直播主播端实现 RTMP 推流协议将数据从主播端推送到服务器；

流媒体服务器负责接收、处理、分发音视频数据的服务，把将推流协议 RTMP 转换为拉流协议 HLS，适配不同的终端和网络，通过 CDN 进行内容分发。用户端通过网络接收到直播的媒体数据。

视频流媒体的分发也常用 P2P 技术，对等网络 P2P（Peer-to-Peer）不依赖中心服务器，通过分散的节点分发从而优化视频流传输，即用户观看视频时，其设备可以同时成为其他用户的源。

除了专有框架，直播系统中常用的流媒体框架包括 RTMP（实时消息传输协议）框架、HLS（HTTP Live Streaming）框架等。RTMP 框架主要用于实现音视频数据的实时传输和控制，而 HLS 框架则主要用于实现音视频数据的分片传输和自适应码率播放。

**4.4**

点播和播放器

区别于直播，点播是用户按需观看预先录制好的内容，比如电影、短视频等，数据被预先存储在了服务器中。

点播框架需要具有高兼容性、高稳定性，需要支持多种音视频格式和编码标准，以确保用户能够播放各种音视频内容。

点播系统完整流程：上传 MP4 文件 → 服务器转码为多码率 HLS → 存储至云端 → 用户点播时播放器根据网速自动选择最佳码率。

点播系统的核心在于播放段，点播系统允许用户根据自己的需求选择、快进、播放内容。在服务器中进行根据不同的网路环境进行转码生成不同码率版本，通过渐进式下载或自适应流传输。

RTSP 服务器可以从实时视频源获取音视频流，并通过 RTSP 将其传输到客户端进行播放，同时支持点播服务。

除了专有框架，点播系统中常用的新媒体播放框架包括各种播放器软件所使用的框架，如 VLC、MPlayer 等。这些框架通常支持多种音视频格式和编码标准，能够解码并播放用户选择的音视频内容。

**4.5**

音视频编辑

在音视频编辑领域，根据编辑平台的不同，每家公司形成了自己的框架，比如桌面端 Adobe Premiere Pro，提供丰富的编辑工具和特效库；移动端 KineMaster，具有轻便、易用和高效的特点；云端 WeVideo，备在线协作、实时预览和分享等功能。

但底层通常依赖于少数开源多媒体处理框架如 GStreamer、FFmpeg 等，GStreamer 的插件化架构适合灵活扩展，但性能优化不如 FFmpeg，在此基础上每家企业常用的模式都是开源 + 自研的组合方案实现最终的项目方案。

文后总结

![](https://mmbiz.qpic.cn/mmbiz_jpg/mpfXeUqqSE8YcXXEE6Tj62xuMSLB3MSyyaCDmnN3Fn2qLeJ5micpIdibtLLRWfRMHbq1f8bOSwjpjXHLmyAoGQCA/640?wx_fmt=jpeg&from=appmsg)

总结来说，关注流媒体的差异，通信协议和流媒体框架，同时还是要多回归到影像上。流媒体的应用，比如监控已经发展很完备了，从 zf 监控到如今的家用监控；直播摄像头发展还是蛮快的，实际看过好几家的产品都在迭代中。

**发展和优化 ---------**

流媒体系统的开发的典型特点一个是最终低延迟和高并发，另一个就是注重传输协议设计以及编解码优化。

当前拥抱 AI 的发展，主要发展还是 AI 实时美颜，AI 语音降噪，边缘计算等。

软件在流媒体的主要的优化方向，在服务器侧主要是降低延迟和高并发，比如减少协议栈层级，容器化部署等；在客户端主要是内存优化，降低功耗。

**赞和关注 ---------**

看到这里还不帮忙点个赞和关注，十分感谢！

其他相关文章可以看：

[Android 音视频多媒体开源框架基础大全](https://mp.weixin.qq.com/s?__biz=MzkxMTUyNTkyNw==&mid=2247484256&idx=1&sn=63a695057639eeaf4814ce225a773a1f&scene=21#wechat_redirect)

[Android 音视频多媒体开源库基础大全](https://mp.weixin.qq.com/s?__biz=MzkxMTUyNTkyNw==&mid=2247484211&idx=1&sn=91611ef6bc4d98a92ed223ab1849e30a&scene=21#wechat_redirect)

![](https://mmbiz.qpic.cn/mmbiz_jpg/mpfXeUqqSEibVeTJAHwKA33aibiaEIIazJZ45lyQGNEL86f3Gf2UfBubFoUQ2ag3lRSsNnkpRO2WcCBUZck7YZVMg/640?wx_fmt=jpeg&from=appmsg)